"""
BaseWinModel v1.1 - çµ±åˆä½¿ç”¨ä¾‹ + Calibration v3 (v2 - æ”¹å–„ç‰ˆ)

å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é€£æº:
1. HorseHistoryStore v2.0
2. RaceFeatureBuilder v5.0
3. BaseFeatureBuilder v2.0
4. BaseWinModel v1.1
5. Calibration v3 (Platt / Isotonic)

v1 ã‹ã‚‰ã®æ”¹å–„ç‚¹:
- ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ä¿®æ­£ï¼ˆval ã§ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
- ç‰¹å¾´é‡æ§‹ç¯‰ã®é–¢æ•°åŒ–
- ä¾‹å¤–å‡¦ç†ã®å¼·åŒ–
- ãƒ­ã‚°å‡ºåŠ›ã®æ”¹å–„
- æ™‚ç³»åˆ—åˆ†å‰²ã®ä¿®æ­£
- val_df ã‚’ä½¿ã£ãŸå­¦ç¿’
- ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®è©•ä¾¡è¿½åŠ 
"""

# æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import logging
import traceback
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any, Optional

# ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£
import pandas as pd
import numpy as np

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from HorseHistoryStore import HorseHistoryStore
from race_feature_builder import RaceFeatureBuilder
from base_feature_builder import BaseFeatureBuilder
from base_model import BaseWinModel, create_win_labels
from calibration import CalibrationConfig, ProbabilityCalibrator

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('base_model_integration.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def create_dummy_data():
    """
    ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆã‚ˆã‚Šç¾å®Ÿçš„ãªç›¸é–¢ã‚’æŒãŸã›ã‚‹ï¼‰
    """
    np.random.seed(42)

    # é¦¬ã®æˆ¦ç¸¾ãƒ‡ãƒ¼ã‚¿ï¼ˆ100ãƒ¬ãƒ¼ã‚¹åˆ†ï¼‰
    n_races = 100
    horses_per_race = 16
    n_total = n_races * horses_per_race

    race_dates = pd.date_range("2024-01-01", periods=n_races, freq="D")

    performance_data = pd.DataFrame({
        "horse_id": [f"horse_{i % 50:03d}" for i in range(n_total)],
        "race_id": [f"race_{i // horses_per_race:04d}" for i in range(n_total)],
        "race_date": np.repeat(race_dates, horses_per_race),
        "race_datetime": np.repeat(
            pd.date_range("2024-01-01 14:00", periods=n_races, freq="D"),
            horses_per_race
        ),
        "track_code": np.random.choice(["æ±äº¬", "ä¸­å±±", "é˜ªç¥"], n_total),
        "course_type": np.random.choice(["èŠ", "ãƒ€ãƒ¼ãƒˆ"], n_total),
        "distance": np.random.choice([1600, 1800, 2000], n_total),
        "field_size": np.repeat(np.random.randint(12, 19, n_races), horses_per_race),
        "corner1_pos": np.random.randint(1, 17, n_total),
        "final_3f_time": np.random.uniform(33, 38, n_total),
        "jockey_id": np.random.choice([f"jockey_{i}" for i in range(20)], n_total),
        "jockey_name": np.random.choice(["æ­¦è±Š", "ãƒ«ãƒ¡ãƒ¼ãƒ«", "ãƒ‡ãƒ ãƒ¼ãƒ­"], n_total),
        "jockey_weight": np.random.uniform(52, 58, n_total),
        "popularity": np.random.randint(1, 17, n_total),
        "remarks": np.random.choice(["", "", "", "", "å‡ºé…ã‚Œ"], n_total),
        "age": np.random.randint(3, 8, n_total),
        "sex": np.random.choice(["ç‰¡", "ç‰", "é¨™"], n_total),
        "career_runs": np.random.randint(1, 30, n_total),
        "frame": [i % horses_per_race + 1 for i in range(n_total)],
        "horse_number": [i % horses_per_race + 1 for i in range(n_total)],
        "weight": np.random.uniform(52, 58, n_total),
        "rest_days": np.random.randint(7, 60, n_total),
    })

    # äººæ°—ã¨ç€é †ã«ç›¸é–¢ã‚’æŒãŸã›ã‚‹
    for race_id in performance_data['race_id'].unique():
        mask = performance_data['race_id'] == race_id
        race_df = performance_data[mask]
        
        # äººæ°—é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_indices = race_df.index[race_df['popularity'].argsort()]
        
        # ä¸Šä½äººæ°—ã»ã©å¥½ç€é †ã®ç¢ºç‡ã‚’é«˜ãï¼ˆãŸã ã—ãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚‚æ®‹ã™ï¼‰
        finish_probs = np.array([
            np.random.beta(2 + (16-i)*0.3, 5 + i*0.2)
            for i in range(1, len(sorted_indices) + 1)
        ])
        
        finish_positions = np.argsort(finish_probs) + 1
        performance_data.loc[sorted_indices, 'finish_position'] = finish_positions

    # ã‚ªãƒƒã‚ºã‚’äººæ°—ã‹ã‚‰ç”Ÿæˆï¼ˆäººæ°—ãŒé«˜ã„ã»ã©ã‚ªãƒƒã‚ºãŒä½ã„ï¼‰
    for race_id in performance_data['race_id'].unique():
        mask = performance_data['race_id'] == race_id
        popularity = performance_data.loc[mask, 'popularity'].values
        
        # äººæ°—ã‹ã‚‰å¤§ã¾ã‹ãªã‚ªãƒƒã‚ºã‚’è¨ˆç®—ï¼ˆ1ç•ªäººæ°—=2å€ç¨‹åº¦ã€16ç•ªäººæ°—=50å€ç¨‹åº¦ï¼‰
        base_odds = 1.5 + (popularity - 1) * 3.0
        noise = np.random.uniform(0.8, 1.2, len(popularity))
        odds = base_odds * noise
        
        performance_data.loc[mask, 'odds'] = odds

    # corner ä½ç½®ã«é€£ç¶šæ€§ã‚’æŒãŸã›ã‚‹
    performance_data['corner2_pos'] = np.clip(
        performance_data['corner1_pos'] + np.random.randint(-2, 3, n_total),
        1, 16
    ).astype(int)
    
    performance_data['corner3_pos'] = np.clip(
        performance_data['corner2_pos'] + np.random.randint(-2, 3, n_total),
        1, 16
    ).astype(int)
    
    performance_data['corner4_pos'] = np.clip(
        performance_data['corner3_pos'] + np.random.randint(-2, 3, n_total),
        1, 16
    ).astype(int)

    # win_flagã‚’è¿½åŠ 
    performance_data["win_flag"] = create_win_labels(
        performance_data["finish_position"],
        positive_up_to=1
    )

    return performance_data


def build_features_for_races(
    race_ids: List[str],
    data: pd.DataFrame,
    history_store: HorseHistoryStore,
    race_builder: RaceFeatureBuilder,
    base_builder: BaseFeatureBuilder,
    dataset_name: str = "train",
) -> pd.DataFrame:
    """
    ãƒ¬ãƒ¼ã‚¹ãƒªã‚¹ãƒˆã‹ã‚‰ç‰¹å¾´é‡ã‚’æ§‹ç¯‰
    
    Args:
        race_ids: ãƒ¬ãƒ¼ã‚¹IDã®ãƒªã‚¹ãƒˆ
        data: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿
        history_store: HorseHistoryStore ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        race_builder: RaceFeatureBuilder ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        base_builder: BaseFeatureBuilder ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        dataset_name: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåï¼ˆãƒ­ã‚°ç”¨ï¼‰
    
    Returns:
        ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    features_list = []
    failed_races = []
    
    logger.info(f"ã€{dataset_name}ã€‘ç‰¹å¾´é‡æ§‹ç¯‰ã‚’é–‹å§‹: {len(race_ids)} ãƒ¬ãƒ¼ã‚¹")
    start_time = time.time()
    
    for i, race_id in enumerate(race_ids):
        try:
            race_mask = data['race_id'] == race_id
            race_df = data[race_mask].copy()

            if len(race_df) == 0:
                logger.warning(f"ãƒ¬ãƒ¼ã‚¹ {race_id} ã®ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                continue
            
            # race_row ã®å®‰å…¨ãªæ§‹ç¯‰
            first_row = race_df.iloc[0]
            
            race_row = {
                "race_id": race_id,
                "race_datetime": first_row["race_datetime"],
                "track_type": first_row["course_type"],
                "distance": first_row["distance"],
                "field_size": first_row["field_size"],
                "track_condition": first_row.get("track_condition", "è‰¯"),
                "course": first_row["track_code"],
                "turn_type": first_row.get("turn_type", "å·¦å›ã‚Š"),
                "track_bias": first_row.get("track_bias", 0.0),
            }

            entries_df = race_df[[
                "horse_id", "jockey_id", "age", "sex", "career_runs",
                "frame", "horse_number", "weight", "rest_days", "odds"
            ]].copy()

            as_of = race_row["race_datetime"]

            # RaceFeatureBuilder
            race_feature_output = race_builder.build_for_race(
                race_row=race_row,
                entries_df=entries_df,
                as_of=as_of,
            )

            # BaseFeatureBuilder
            features_df = base_builder.build_features_for_race(
                entries_df=entries_df,
                race_row=race_row,
                as_of=as_of,
                race_feature_output=race_feature_output,
            )

            # ãƒ©ãƒ™ãƒ«è¿½åŠ 
            features_df["race_id"] = race_id
            features_df["win_flag"] = race_df["win_flag"].values
            features_df["finish_position"] = race_df["finish_position"].values
            
            # odds ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ï¼ˆè©•ä¾¡ç”¨ï¼‰
            features_df["odds"] = race_df["odds"].values

            features_list.append(features_df)
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤ºï¼ˆ10ãƒ¬ãƒ¼ã‚¹ã”ã¨ï¼‰
            if (i + 1) % 10 == 0:
                logger.info(f"  é€²æ—: {i+1}/{len(race_ids)} ãƒ¬ãƒ¼ã‚¹å®Œäº†")
                
        except Exception as e:
            logger.error(
                f"ãƒ¬ãƒ¼ã‚¹ {race_id} ã®ç‰¹å¾´é‡æ§‹ç¯‰ã«å¤±æ•—: {e}\n"
                f"{traceback.format_exc()}"
            )
            failed_races.append({
                "race_id": race_id,
                "error": str(e),
                "traceback": traceback.format_exc(),
            })
            continue

    if not features_list:
        raise ValueError(f"{dataset_name}: å…¨ã¦ã®ãƒ¬ãƒ¼ã‚¹ã§ç‰¹å¾´é‡æ§‹ç¯‰ã«å¤±æ•—ã—ã¾ã—ãŸ")

    features = pd.concat(features_list, ignore_index=True)
    
    elapsed = time.time() - start_time
    logger.info(
        f"ã€{dataset_name}ã€‘ç‰¹å¾´é‡æ§‹ç¯‰å®Œäº†: "
        f"{len(features)} è¡Œ, {len(features.columns)} åˆ—, "
        f"{elapsed:.2f} ç§’"
    )
    
    # å¤±æ•—ãƒ¬ãƒ¼ã‚¹ã®è­¦å‘Š
    if failed_races:
        logger.warning(
            f"{len(failed_races)}/{len(race_ids)} ãƒ¬ãƒ¼ã‚¹ã§æ§‹ç¯‰å¤±æ•— "
            f"({len(failed_races)/len(race_ids)*100:.1f}%)"
        )
        
        # å¤±æ•—ãŒå¤šã„å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        if len(failed_races) > len(race_ids) * 0.1:
            import json
            error_log_path = f"failed_races_{dataset_name}.json"
            with open(error_log_path, "w") as f:
                json.dump(failed_races, f, indent=2, ensure_ascii=False)
            logger.warning(f"å¤±æ•—ãƒ¬ãƒ¼ã‚¹ã®è©³ç´°ã‚’ä¿å­˜: {error_log_path}")
    
    return features


def main():
    """çµ±åˆãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ"""
    
    overall_start = time.time()
    
    logger.info("=" * 80)
    logger.info("BaseWinModel v1.1 - çµ±åˆä½¿ç”¨ä¾‹ (+ Calibration v3) v2")
    logger.info("=" * 80)

    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—1ã€‘ãƒ‡ãƒ¼ã‚¿æº–å‚™")
    performance_data = create_dummy_data()

    logger.info(f"  ç·ãƒ¬ãƒ¼ã‚¹æ•°: {performance_data['race_id'].nunique()}")
    logger.info(f"  ç·èµ°æ•°: {len(performance_data)}")
    logger.info(f"  å‹ã¡æ•°: {performance_data['win_flag'].sum()}")

    # å­¦ç¿’ãƒ»æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆåˆ†å‰²ï¼ˆæ™‚ç³»åˆ—å³å®ˆï¼‰
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—2ã€‘ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆæ™‚ç³»åˆ—ï¼‰")
    
    # race_date ã§ã‚½ãƒ¼ãƒˆã—ã¦ã‹ã‚‰åˆ†å‰²ï¼ˆCritical ä¿®æ­£ï¼‰
    race_info = performance_data[['race_id', 'race_date']].drop_duplicates()
    race_info = race_info.sort_values('race_date')
    race_ids_sorted = race_info['race_id'].values
    
    n_races = len(race_ids_sorted)
    train_size = int(n_races * 0.6)
    val_size = int(n_races * 0.2)

    train_races = race_ids_sorted[:train_size]
    val_races = race_ids_sorted[train_size:train_size + val_size]
    test_races = race_ids_sorted[train_size + val_size:]

    train_data = performance_data[performance_data['race_id'].isin(train_races)]
    val_data = performance_data[performance_data['race_id'].isin(val_races)]
    test_data = performance_data[performance_data['race_id'].isin(test_races)]

    logger.info(f"  å­¦ç¿’: {len(train_data)}èµ°ï¼ˆ{len(train_races)}ãƒ¬ãƒ¼ã‚¹ï¼‰")
    logger.info(f"  æ¤œè¨¼: {len(val_data)}èµ°ï¼ˆ{len(val_races)}ãƒ¬ãƒ¼ã‚¹ï¼‰")
    logger.info(f"  ãƒ†ã‚¹ãƒˆ: {len(test_data)}èµ°ï¼ˆ{len(test_races)}ãƒ¬ãƒ¼ã‚¹ï¼‰")
    
    # æ—¥ä»˜ç¯„å›²ã®ç¢ºèª
    logger.info(f"  å­¦ç¿’æœŸé–“: {train_data['race_date'].min()} ã€œ {train_data['race_date'].max()}")
    logger.info(f"  æ¤œè¨¼æœŸé–“: {val_data['race_date'].min()} ã€œ {val_data['race_date'].max()}")
    logger.info(f"  ãƒ†ã‚¹ãƒˆæœŸé–“: {test_data['race_date'].min()} ã€œ {test_data['race_date'].max()}")

    # HorseHistoryStoreåˆæœŸåŒ–
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—3ã€‘HorseHistoryStoreåˆæœŸåŒ–")
    history_store = HorseHistoryStore(performance_data)
    logger.info("  âœ… å®Œäº†")

    # RaceFeatureBuilderåˆæœŸåŒ–
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—4ã€‘RaceFeatureBuilderåˆæœŸåŒ–")
    race_builder = RaceFeatureBuilder(history_store)
    logger.info("  âœ… å®Œäº†")

    # BaseFeatureBuilderåˆæœŸåŒ–
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—5ã€‘BaseFeatureBuilderåˆæœŸåŒ–")
    base_builder = BaseFeatureBuilder(history_store)
    logger.info("  âœ… å®Œäº†")

    # ç‰¹å¾´é‡æ§‹ç¯‰ï¼ˆé–¢æ•°åŒ–ã«ã‚ˆã‚Šé‡è¤‡å‰Šæ¸›ï¼‰
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—6ã€‘ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹ç¯‰")
    
    train_features = build_features_for_races(
        race_ids=train_races,
        data=train_data,
        history_store=history_store,
        race_builder=race_builder,
        base_builder=base_builder,
        dataset_name="train",
    )
    
    val_features = build_features_for_races(
        race_ids=val_races,
        data=val_data,
        history_store=history_store,
        race_builder=race_builder,
        base_builder=base_builder,
        dataset_name="val",
    )

    # BaseWinModelåˆæœŸåŒ–ãƒ»å­¦ç¿’
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—7ã€‘BaseWinModelåˆæœŸåŒ–ãƒ»å­¦ç¿’")
    model = BaseWinModel()

    # val_df ã‚’ä½¿ã£ã¦å­¦ç¿’ï¼ˆCritical ä¿®æ­£: early stopping æœ‰åŠ¹åŒ–ï¼‰
    model.fit(
        train_df=train_features,
        feature_cols=None,  # è‡ªå‹•æ¨å®š
        target_col="win_flag",
        val_df=val_features,  # early stopping æœ‰åŠ¹åŒ–
    )

    logger.info(f"  âœ… å­¦ç¿’å®Œäº†")
    logger.info(f"    - ä½¿ç”¨ç‰¹å¾´é‡æ•°: {len(model.feature_cols)}")
    logger.info(f"    - ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡æ•°: {len(model.categorical_features)}")

    # ç‰¹å¾´é‡é‡è¦åº¦
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—8ã€‘ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆä¸Šä½10ä»¶ï¼‰")
    importance_df = model.get_feature_importance(top_n=10)
    for i, row in importance_df.iterrows():
        logger.info(f"    {i+1:2d}. {row['feature']:30s} {row['importance']:10.0f}")

    # äºˆæ¸¬
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—9ã€‘äºˆæ¸¬ï¼ˆå­¦ç¿’ãƒ»æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ï¼‰")
    train_probs = model.predict_proba(train_features)
    val_probs = model.predict_proba(val_features)
    
    logger.info(f"  âœ… äºˆæ¸¬å®Œäº†")
    logger.info(f"    - å­¦ç¿’ãƒ‡ãƒ¼ã‚¿äºˆæ¸¬ç¯„å›²: {train_probs.min():.4f} ã€œ {train_probs.max():.4f}")
    logger.info(f"    - æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿äºˆæ¸¬ç¯„å›²: {val_probs.min():.4f} ã€œ {val_probs.max():.4f}")

    # odds ã‚«ãƒ©ãƒ ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯ï¼ˆCritical ä¿®æ­£ï¼‰
    odds_col = "odds_raw" if "odds_raw" in train_features.columns else "odds"
    
    if odds_col not in train_features.columns:
        logger.warning(f"è­¦å‘Š: {odds_col} ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚è©•ä¾¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        odds_train = None
        odds_val = None
    else:
        odds_train = train_features[odds_col]
        odds_val = val_features[odds_col]

    # è©•ä¾¡
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—10ã€‘è©•ä¾¡ï¼ˆå­¦ç¿’ãƒ»æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ï¼‰")
    
    if odds_train is not None:
        train_metrics = model.evaluate(
            df=train_features,
            y=train_features["win_flag"],
            race_ids=train_features["race_id"],
            finish_positions=train_features["finish_position"],
            odds=odds_train,
        )

        logger.info("  å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è©•ä¾¡:")
        for key, value in train_metrics.items():
            logger.info(f"    - {key:20s}: {value:.4f}")
    
    if odds_val is not None:
        val_metrics = model.evaluate(
            df=val_features,
            y=val_features["win_flag"],
            race_ids=val_features["race_id"],
            finish_positions=val_features["finish_position"],
            odds=odds_val,
        )

        logger.info("  æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿è©•ä¾¡:")
        for key, value in val_metrics.items():
            logger.info(f"    - {key:20s}: {value:.4f}")

    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—11ã€‘ãƒ¢ãƒ‡ãƒ«ä¿å­˜")
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    MODEL_DIR = Path("./models")
    MODEL_DIR.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_path = MODEL_DIR / f"base_win_model_{timestamp}.txt"
    
    model.save(str(model_path))
    logger.info(f"  âœ… ä¿å­˜å®Œäº†: {model_path}")

    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—12ã€‘ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿")
    model2 = BaseWinModel()
    model2.load(str(model_path))
    logger.info("  âœ… èª­ã¿è¾¼ã¿å®Œäº†")

    # èª­ã¿è¾¼ã¿å¾Œã®äºˆæ¸¬
    train_probs2 = model2.predict_proba(train_features)
    diff = np.abs(train_probs - train_probs2).max()
    logger.info(f"  ç¢ºèª: äºˆæ¸¬å€¤ã®å·®ï¼ˆmaxï¼‰= {diff:.10f}")

    if diff < 1e-6:
        logger.info("  âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿OK")
    else:
        logger.warning("  âš ï¸ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ã«å•é¡Œã‚ã‚Š")

    # ğŸ”½ã€ã‚¹ãƒ†ãƒƒãƒ—13ã€‘Calibration v3 ã«ã‚ˆã‚‹ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—13ã€‘ç¢ºç‡ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (Calibration v3)")

    # Critical ä¿®æ­£: val ã§ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    calib_config = CalibrationConfig(method="platt", n_bins=15)
    calibrator = ProbabilityCalibrator(calib_config)

    logger.info("  æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’å­¦ç¿’...")
    calibrator.fit(val_probs, val_features["win_flag"].values)

    # è©•ä¾¡ï¼ˆæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ï¼‰
    calib_metrics = calibrator.evaluate(val_probs, val_features["win_flag"].values)

    logger.info("  ğŸ“Š Calibration æŒ‡æ¨™ï¼ˆæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ï¼‰")
    logger.info(f"    - ECE  Before: {calib_metrics['ece_raw']:.6f}")
    logger.info(f"    - ECE  After : {calib_metrics['ece_calibrated']:.6f}")
    logger.info(f"    - æ”¹å–„ç‡: {(1 - calib_metrics['ece_calibrated']/calib_metrics['ece_raw'])*100:.1f}%")
    logger.info(f"    - Brier Before: {calib_metrics['brier_raw']:.6f}")
    logger.info(f"    - Brier After : {calib_metrics['brier_calibrated']:.6f}")

    # ECE ãŒæ”¹å–„ã—ã¦ã„ãªã„å ´åˆã¯è­¦å‘Š
    if calib_metrics['ece_calibrated'] >= calib_metrics['ece_raw']:
        logger.warning("  âš ï¸ ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ ECE ãŒæ”¹å–„ã—ã¦ã„ã¾ã›ã‚“")

    # ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¾Œã®ç¢ºç‡ä¾‹
    calibrated_val_probs = calibrator.predict(val_probs)
    
    logger.info("\n  ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å…ˆé ­10ä»¶ï¼‰:")
    for i in range(min(10, len(calibrated_val_probs))):
        logger.info(
            f"    raw={val_probs[i]:.4f}  "
            f"calib={calibrated_val_probs[i]:.4f}  "
            f"y={int(val_features['win_flag'].iloc[i])}"
        )

    # Reliability Curve ã®å–å¾—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    bin_centers, bin_acc, bin_conf = calibrator.get_reliability_curve(
        val_features["win_flag"].values,
        val_probs,
        n_bins=10
    )
    
    logger.info("\n  Reliability Curve:")
    for i in range(len(bin_centers)):
        if not np.isnan(bin_acc[i]):
            logger.info(
                f"    Bin {i+1:2d} (ä¸­å¿ƒ={bin_centers[i]:.2f}): "
                f"äºˆæ¸¬={bin_conf[i]:.4f}, å®Ÿéš›={bin_acc[i]:.4f}"
            )

    # ğŸ”½ã€ã‚¹ãƒ†ãƒƒãƒ—14ã€‘ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æœ€çµ‚è©•ä¾¡
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—14ã€‘ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æœ€çµ‚è©•ä¾¡")
    
    test_features = build_features_for_races(
        race_ids=test_races,
        data=test_data,
        history_store=history_store,
        race_builder=race_builder,
        base_builder=base_builder,
        dataset_name="test",
    )
    
    # äºˆæ¸¬
    test_probs_raw = model.predict_proba(test_features)
    test_probs_calibrated = calibrator.predict(test_probs_raw)
    
    logger.info(f"  âœ… äºˆæ¸¬å®Œäº†")
    logger.info(f"    - äºˆæ¸¬ç¯„å›²ï¼ˆrawï¼‰: {test_probs_raw.min():.4f} ã€œ {test_probs_raw.max():.4f}")
    logger.info(f"    - äºˆæ¸¬ç¯„å›²ï¼ˆcalibï¼‰: {test_probs_calibrated.min():.4f} ã€œ {test_probs_calibrated.max():.4f}")
    
    # ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
    if odds_col in test_features.columns:
        test_metrics = model.evaluate(
            df=test_features,
            y=test_features["win_flag"],
            race_ids=test_features["race_id"],
            finish_positions=test_features["finish_position"],
            odds=test_features[odds_col],
        )

        logger.info("  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ ãƒ¢ãƒ‡ãƒ«è©•ä¾¡:")
        for key, value in test_metrics.items():
            logger.info(f"    - {key:20s}: {value:.4f}")
    
    # ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡
    test_calib_metrics = calibrator.evaluate(
        test_probs_raw,
        test_features["win_flag"].values
    )
    
    logger.info("\n  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³:")
    logger.info(f"    - ECE (raw):        {test_calib_metrics['ece_raw']:.6f}")
    logger.info(f"    - ECE (calibrated): {test_calib_metrics['ece_calibrated']:.6f}")
    logger.info(f"    - Brier (raw):      {test_calib_metrics['brier_raw']:.6f}")
    logger.info(f"    - Brier (calibrated): {test_calib_metrics['brier_calibrated']:.6f}")

    # å‡¦ç†æ™‚é–“
    overall_elapsed = time.time() - overall_start
    
    logger.info("\n" + "=" * 80)
    logger.info("âœ… BaseWinModel v1.1 + Calibration v3 - çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†")
    logger.info(f"ç·å‡¦ç†æ™‚é–“: {overall_elapsed:.2f} ç§’")
    logger.info("=" * 80)

    logger.info("\nã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã€‘")
    logger.info("1. âœ… ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ä¿®æ­£å®Œäº†ï¼ˆval ã§ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰")
    logger.info("2. âœ… æ™‚ç³»åˆ—åˆ†å‰²ä¿®æ­£å®Œäº†ï¼ˆrace_date ã§ã‚½ãƒ¼ãƒˆï¼‰")
    logger.info("3. âœ… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿è©•ä¾¡è¿½åŠ å®Œäº†")
    logger.info("4. æ¬¡ã¯å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®å­¦ç¿’ãƒ»è©•ä¾¡ãƒ»ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’è¡Œã†ã€‚")
    logger.info("5. PaceAdjustment ã¨çµ±åˆã—ãŸ end-to-end ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¸æ¥ç¶šã™ã‚‹ã€‚")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        logger.error(traceback.format_exc())
        raise
