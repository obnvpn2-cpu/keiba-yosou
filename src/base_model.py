"""
BaseWinModel v1.1 - ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³å®Œæˆç‰ˆ

v1.1ï¼ˆ2024-12-04ï¼‰: å®Ÿå‹™ãƒ¬ãƒ™ãƒ«å®Œå…¨ä¿®æ­£
ğŸ”¥ ä¿®æ­£å†…å®¹:
1. predict_for_race()ã‚’éæ¨å¥¨åŒ–ï¼ˆå¤–éƒ¨ãƒ˜ãƒ«ãƒ‘ãƒ¼ã«ç§»è¡Œæ¨å¥¨ï¼‰
2. ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã®è‡ªå‹•åˆ¤å®šã‚’æ”¹å–„ï¼ˆpd.api.typesä½¿ç”¨ï¼‰
3. best_iterationã®å–å¾—ã‚’æ”¹å–„ï¼ˆ-1ãƒã‚§ãƒƒã‚¯ï¼‰
4. early_stoppingã‚’æ”¹å–„ï¼ˆval_dfãŒãªã„å ´åˆã¯ç„¡åŠ¹åŒ–ï¼‰
5. positive_up_toã‚’configã‹ã‚‰å‰Šé™¤
6. NDCGã‚’å˜ç€ã®ã¿ã«ä¿®æ­£
7. è©•ä¾¡é–¢æ•°ã‚’æ”¹å–„ï¼ˆä¾‹å¤–å‡¦ç†ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€groupbyä½¿ç”¨ï¼‰
8. docstringã‚’å®Œå…¨è¿½åŠ 
9. å‹ãƒ’ãƒ³ãƒˆã‚’å®Œå…¨è¿½åŠ 
10. save/loadã‚’æ”¹å–„ï¼ˆãƒ‘ã‚¹ç®¡ç†æ˜ç¢ºåŒ–ï¼‰
11. feature_colsã®è‡ªå‹•æ¨å®šæ©Ÿèƒ½ã‚’è¿½åŠ 
12. EVãƒ™ãƒ¼ã‚¹å›åç‡ã®é–¾å€¤ã‚’configã«è¿½åŠ 
13. verboseè¨­å®šã‚’è¿½åŠ 

v1.0: åˆç‰ˆï¼ˆChatGPTç‰ˆ - å¤šæ•°ã®å•é¡Œã‚ã‚Šï¼‰
"""

from __future__ import annotations

from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Mapping
import warnings

import numpy as np
import pandas as pd
import lightgbm as lgb
from sklearn.metrics import (
    brier_score_loss,
    log_loss,
    roc_auc_score,
    ndcg_score,
)


@dataclass
class BaseWinModelConfig:
    """
    BaseWinModel ã®è¨­å®šï¼ˆv1.1æ”¹å–„ç‰ˆï¼‰
    
    ğŸ”¥ v1.1: positive_up_toå‰Šé™¤ã€ev_thresholdè¿½åŠ ã€verboseè¿½åŠ 
    """

    lgbm_params: Dict[str, Any] = field(
        default_factory=lambda: {
            "objective": "binary",
            "metric": ["binary_logloss", "auc"],
            "boosting_type": "gbdt",
            "learning_rate": 0.03,
            "num_leaves": 63,
            "max_depth": -1,
            "min_child_samples": 100,
            "subsample": 0.7,
            "colsample_bytree": 0.6,
            "reg_alpha": 1.0,
            "reg_lambda": 1.0,
            "verbose": -1,
        }
    )
    num_boost_round: int = 1000
    early_stopping_rounds: int = 50
    
    # ğŸ”¥ v1.1: æ–°è¦è¿½åŠ 
    ev_threshold: float = 0.15  # EVãƒ™ãƒ¼ã‚¹å›åç‡ã®è³¼å…¥é–¾å€¤
    verbose: int = 0  # å­¦ç¿’æ™‚ã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«


class BaseWinModel:
    """
    å˜å‹å‹ç‡ã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆv1.1æ”¹å–„ç‰ˆï¼‰
    
    å½¹å‰²:
    - ãƒšãƒ¼ã‚¹ãƒ»é¦¬å ´è£œæ­£å‰ã®ç´ ã®å‹ç‡ã‚’äºˆæ¸¬
    - BaseFeatureBuilderãŒç”Ÿæˆã—ãŸç‰¹å¾´é‡ã‚’å…¥åŠ›
    - LightGBMã«ã‚ˆã‚‹äºŒå€¤åˆ†é¡
    
    å…¥åŠ›:
    - BaseFeatureBuilder ãŒç”Ÿæˆã—ãŸç‰¹å¾´é‡ DataFrame
    
    å‡ºåŠ›:
    - å‹ç‡ï¼ˆ0ã€œ1ï¼‰
    
    ğŸ”¥ v1.1: å®Ÿå‹™ãƒ¬ãƒ™ãƒ«å®Œå…¨ä¿®æ­£
    """

    VERSION = "v1.1"

    def __init__(self, config: Optional[BaseWinModelConfig] = None) -> None:
        """
        Args:
            config: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        """
        self.config = config or BaseWinModelConfig()
        self.model: Optional[lgb.Booster] = None
        self.feature_cols: List[str] = []
        self.categorical_features: List[str] = []
        self._fitted: bool = False

    # ------------------------------------------------------------------
    # å†…éƒ¨: ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡æ¤œå‡ºï¼ˆv1.1æ”¹å–„ç‰ˆï¼‰
    # ------------------------------------------------------------------
    def _detect_categorical_features(self, X: pd.DataFrame) -> List[str]:
        """
        ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã‚’è‡ªå‹•åˆ¤åˆ¥ï¼ˆv1.1æ”¹å–„ç‰ˆï¼‰
        
        ğŸ”¥ v1.1: pd.api.typesä½¿ç”¨ã€åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯æ”¹å–„
        
        æ¤œå‡ºåŸºæº–:
        - object / category å‹
        - intå‹ã‹ã¤ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°ãŒ2ã€œ20ï¼ˆé€£ç•ªç³»ã¯é™¤å¤–ï¼‰
        
        Args:
            X: ç‰¹å¾´é‡DataFrame
        
        Returns:
            ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡åãƒªã‚¹ãƒˆ
        """
        categorical_cols: List[str] = []

        # ğŸ”¥ v1.1: BaseFeatureBuilder v2.0ã¨æ•´åˆ
        exclude_cols = [
            "horse_id",
            "race_id",
            "horse_number",
            "frame",
        ]

        for col in X.columns:
            if col in exclude_cols:
                continue

            # object / categoryå‹
            if pd.api.types.is_object_dtype(X[col]) or pd.api.types.is_categorical_dtype(X[col]):
                categorical_cols.append(col)
                continue
            
            # ğŸ”¥ v1.1: is_integer_dtype()ã‚’ä½¿ç”¨
            if pd.api.types.is_integer_dtype(X[col]):
                n_unique = X[col].nunique()
                # 2å€¤ä»¥ä¸Š20å€¤ä»¥ä¸‹ã‚’ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ã¨ã¿ãªã™
                if 2 <= n_unique <= 20:
                    categorical_cols.append(col)

        return categorical_cols

    # ------------------------------------------------------------------
    # å­¦ç¿’ï¼ˆv1.1æ”¹å–„ç‰ˆï¼‰
    # ------------------------------------------------------------------
    def fit(
        self,
        train_df: pd.DataFrame,
        *,
        feature_cols: Optional[List[str]] = None,
        target_col: str = "win_flag",
        val_df: Optional[pd.DataFrame] = None,
    ) -> None:
        """
        ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰LightGBMã‚’å­¦ç¿’ï¼ˆv1.1æ”¹å–„ç‰ˆï¼‰
        
        ğŸ”¥ v1.1: feature_colsè‡ªå‹•æ¨å®šã€early_stoppingæ”¹å–„
        
        Args:
            train_df: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆç‰¹å¾´é‡ + ãƒ©ãƒ™ãƒ«ï¼‰
            feature_cols: ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã‚«ãƒ©ãƒ åï¼ˆNoneã®å ´åˆã¯è‡ªå‹•æ¨å®šï¼‰
            target_col: ãƒ©ãƒ™ãƒ«åˆ—åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: "win_flag"ï¼‰
            val_df: æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ï¼ˆearly stoppingç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
        Raises:
            ValueError: target_colãŒå­˜åœ¨ã—ãªã„å ´åˆ
            ValueError: æŒ‡å®šã•ã‚ŒãŸfeature_colsãŒå­˜åœ¨ã—ãªã„å ´åˆ
        """
        if target_col not in train_df.columns:
            raise ValueError(f"target_col '{target_col}' ãŒ train_df ã«å­˜åœ¨ã—ã¾ã›ã‚“")

        # ğŸ”¥ v1.1: feature_colsè‡ªå‹•æ¨å®š
        if feature_cols is None:
            exclude_cols = ["horse_id", "race_id", target_col]
            self.feature_cols = [c for c in train_df.columns if c not in exclude_cols]
            warnings.warn(
                f"feature_colsãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€{len(self.feature_cols)}å€‹ã®ç‰¹å¾´é‡ã‚’è‡ªå‹•æ¨å®šã—ã¾ã—ãŸã€‚"
            )
        else:
            # å­˜åœ¨ç¢ºèª
            missing = set(feature_cols) - set(train_df.columns)
            if missing:
                raise ValueError(f"æŒ‡å®šã•ã‚ŒãŸç‰¹å¾´é‡ãŒ train_df ã«å­˜åœ¨ã—ã¾ã›ã‚“: {missing}")
            self.feature_cols = list(feature_cols)

        X_train = train_df[self.feature_cols]
        y_train = train_df[target_col].astype(float)

        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«è‡ªå‹•åˆ¤å®š
        self.categorical_features = self._detect_categorical_features(X_train)

        train_data = lgb.Dataset(
            X_train,
            label=y_train,
            categorical_feature=self.categorical_features or None,
            free_raw_data=False,
        )

        valid_sets = [train_data]
        valid_names = ["train"]

        # ğŸ”¥ v1.1: val_dfã®å‡¦ç†ã‚’æ”¹å–„
        if val_df is not None:
            if target_col not in val_df.columns:
                raise ValueError(f"target_col '{target_col}' ãŒ val_df ã«å­˜åœ¨ã—ã¾ã›ã‚“")
            X_val = val_df[self.feature_cols]
            y_val = val_df[target_col].astype(float)
            val_data = lgb.Dataset(
                X_val,
                label=y_val,
                reference=train_data,
                categorical_feature=self.categorical_features or None,
                free_raw_data=False,
            )
            valid_sets.append(val_data)
            valid_names.append("valid")
        else:
            val_data = None

        # ğŸ”¥ v1.1: early_stoppingã¯val_dfãŒã‚ã‚‹å ´åˆã®ã¿
        callbacks = []
        if val_df is not None:
            callbacks.append(
                lgb.early_stopping(
                    self.config.early_stopping_rounds,
                    verbose=bool(self.config.verbose),
                )
            )
        
        if self.config.verbose > 0:
            callbacks.append(lgb.log_evaluation(period=100))

        self.model = lgb.train(
            self.config.lgbm_params,
            train_data,
            num_boost_round=self.config.num_boost_round,
            valid_sets=valid_sets,
            valid_names=valid_names,
            callbacks=callbacks or None,
        )

        self._fitted = True

    # ------------------------------------------------------------------
    # äºˆæ¸¬ï¼ˆv1.1æ”¹å–„ç‰ˆï¼‰
    # ------------------------------------------------------------------
    def predict_proba(self, df: pd.DataFrame) -> np.ndarray:
        """
        å‹ç‡ã‚’äºˆæ¸¬ï¼ˆv1.1æ”¹å–„ç‰ˆï¼‰
        
        ğŸ”¥ v1.1: best_iterationå–å¾—ã‚’æ”¹å–„
        
        Args:
            df: BaseFeatureBuilder ãŒç”Ÿæˆã—ãŸç‰¹å¾´é‡ DataFrame
        
        Returns:
            shape = (N,) ã® numpy arrayï¼ˆ0ã€œ1ï¼‰
        
        Raises:
            ValueError: ãƒ¢ãƒ‡ãƒ«ãŒæœªå­¦ç¿’ã®å ´åˆ
        """
        if not self._fitted or self.model is None:
            raise ValueError(
                "BaseWinModel ãŒã¾ã å­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚fit() ã‚’å…ˆã«å‘¼ã‚“ã§ãã ã•ã„ã€‚"
            )

        X = df[self.feature_cols]
        
        # ğŸ”¥ v1.1: best_iterationå–å¾—ã‚’æ”¹å–„
        num_iter = self.model.best_iteration
        if num_iter < 0:
            num_iter = self.model.current_iteration()
        
        preds = self.model.predict(X, num_iteration=num_iter)
        return preds.astype(float)

    # ------------------------------------------------------------------
    # ãƒ¬ãƒ¼ã‚¹å˜ä½ã®äºˆæ¸¬ï¼ˆv1.1éæ¨å¥¨åŒ–ï¼‰
    # ------------------------------------------------------------------
    def predict_for_race(
        self,
        entries_df: pd.DataFrame,
        race_row: Mapping[str, Any],
        as_of: Any,
        race_feature_builder: Any,  # RaceFeatureBuilder
        feature_builder: Any,       # BaseFeatureBuilder
    ) -> Dict[str, float]:
        """
        å®Ÿé‹ç”¨æ™‚ç”¨ã®ç°¡æ˜“APIï¼ˆv1.1éæ¨å¥¨ï¼‰
        
        ğŸ”¥ v1.1: éæ¨å¥¨åŒ–
        
        ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹ã«æ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å«ã‚ã‚‹ãŸã‚ã€
        è²¬å‹™ãŒæ··ä¹±ã—ã¾ã™ã€‚ä»£ã‚ã‚Šã«å¤–éƒ¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã®ä½¿ç”¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚
        
        æ¨å¥¨å®Ÿè£…:
        ```python
        def predict_win_probs(
            base_model: BaseWinModel,
            entries_df: pd.DataFrame,
            race_row: Mapping[str, Any],
            as_of: Any,
            race_feature_builder: RaceFeatureBuilder,
            feature_builder: BaseFeatureBuilder,
        ) -> Dict[str, float]:
            # å¤–éƒ¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã¨ã—ã¦å®Ÿè£…
        ```
        
        Args:
            entries_df: å‡ºé¦¬è¡¨
            race_row: ãƒ¬ãƒ¼ã‚¹æƒ…å ±
            as_of: åŸºæº–æ—¥æ™‚
            race_feature_builder: RaceFeatureBuilder v5
            feature_builder: BaseFeatureBuilder v2
        
        Returns:
            {horse_id: win_prob}
        """
        warnings.warn(
            "predict_for_race()ã¯éæ¨å¥¨ã§ã™ã€‚å¤–éƒ¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã®ä½¿ç”¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚",
            DeprecationWarning,
            stacklevel=2,
        )
        
        if "horse_id" not in entries_df.columns:
            raise ValueError("entries_df ã« 'horse_id' ã‚«ãƒ©ãƒ ãŒå¿…è¦ã§ã™ã€‚")

        race_feature_output = race_feature_builder.build_for_race(
            race_row=race_row,
            entries_df=entries_df,
            as_of=as_of,
        )

        feat_df = feature_builder.build_features_for_race(
            entries_df=entries_df,
            race_row=race_row,
            as_of=as_of,
            race_feature_output=race_feature_output,
        )

        probs = self.predict_proba(feat_df)
        horse_ids = feat_df["horse_id"].astype(str).tolist()

        return {hid: float(p) for hid, p in zip(horse_ids, probs)}

    # ------------------------------------------------------------------
    # è©•ä¾¡ï¼ˆv1.1æ”¹å–„ç‰ˆï¼‰
    # ------------------------------------------------------------------
    def evaluate(
        self,
        df: pd.DataFrame,
        y: pd.Series,
        race_ids: Optional[pd.Series] = None,
        finish_positions: Optional[pd.Series] = None,
        odds: Optional[pd.Series] = None,
        ev_threshold: Optional[float] = None,
    ) -> Dict[str, float]:
        """
        åŒ…æ‹¬çš„ãªè©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—ï¼ˆv1.1æ”¹å–„ç‰ˆï¼‰
        
        ğŸ”¥ v1.1: ä¾‹å¤–å‡¦ç†æ”¹å–„ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ã€NDCGä¿®æ­£
        
        Args:
            df: ç‰¹å¾´é‡DataFrame
            y: çœŸã®ãƒ©ãƒ™ãƒ«ï¼ˆ0/1ï¼‰
            race_ids: ãƒ¬ãƒ¼ã‚¹IDï¼ˆãƒ¬ãƒ¼ã‚¹å˜ä½è©•ä¾¡ç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            finish_positions: ç€é †ï¼ˆNDCGè¨ˆç®—ç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            odds: ã‚ªãƒƒã‚ºï¼ˆå›åç‡è¨ˆç®—ç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            ev_threshold: EVè³¼å…¥é–¾å€¤ï¼ˆNoneã®å ´åˆã¯configã‹ã‚‰å–å¾—ï¼‰
        
        Returns:
            è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¾æ›¸:
                - brier_score: Brierã‚¹ã‚³ã‚¢
                - log_loss: å¯¾æ•°æå¤±
                - auc: ROC-AUC
                - ndcg: NDCGï¼ˆãƒ¬ãƒ¼ã‚¹å˜ä½ã€1ç€ã®ã¿è©•ä¾¡ï¼‰
                - top1_accuracy: ãƒ¬ãƒ¼ã‚¹å˜ä½æ­£è§£ç‡
                - recovery_rate_ev: EVãƒ™ãƒ¼ã‚¹å›åç‡
        """
        y = y.astype(int)
        y_pred = self.predict_proba(df)

        metrics: Dict[str, float] = {}

        # 1. Brier Score
        metrics["brier_score"] = float(brier_score_loss(y, y_pred))

        # 2. Log Loss
        metrics["log_loss"] = float(log_loss(y, y_pred))

        # 3. AUCï¼ˆv1.1æ”¹å–„ç‰ˆï¼‰
        try:
            metrics["auc"] = float(roc_auc_score(y, y_pred))
        except ValueError as e:
            warnings.warn(
                f"AUCè¨ˆç®—ã«å¤±æ•—: {e}ï¼ˆå…¨ã¦ã®ãƒ©ãƒ™ãƒ«ãŒåŒã˜å€¤ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰"
            )
            metrics["auc"] = float("nan")

        # ãƒ¬ãƒ¼ã‚¹å˜ä½è©•ä¾¡ãŒä¸è¦ãªå ´åˆã¯ã“ã“ã§çµ‚äº†
        if race_ids is None:
            return metrics

        # 4. NDCGï¼ˆv1.1ä¿®æ­£ç‰ˆ: å˜ç€ã®ã¿è©•ä¾¡ï¼‰
        if finish_positions is not None:
            ndcg_scores: List[float] = []
            
            # ğŸ”¥ v1.1: groupbyã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„
            for rid, indices in pd.Series(race_ids).groupby(race_ids).groups.items():
                pos = finish_positions.iloc[indices].values
                pred = y_pred[indices]

                if len(pos) <= 1:
                    continue

                # ğŸ”¥ v1.1: å˜ç€ã®ã¿è©•ä¾¡ï¼ˆ1ç€=1, ãã‚Œä»¥å¤–=0ï¼‰
                true_rel = (pos == 1).astype(int).reshape(1, -1)
                pred_scores = pred.reshape(1, -1)

                try:
                    ndcg = ndcg_score(true_rel, pred_scores)
                    ndcg_scores.append(float(ndcg))
                except Exception as e:
                    warnings.warn(f"NDCGè¨ˆç®—ã«å¤±æ•—ï¼ˆãƒ¬ãƒ¼ã‚¹{rid}ï¼‰: {e}")
                    continue

            if ndcg_scores:
                metrics["ndcg"] = float(np.mean(ndcg_scores))

        # 5. Top-1 Accuracyï¼ˆãƒ¬ãƒ¼ã‚¹å˜ä½ï¼‰
        top1_correct = 0
        total_races = 0
        
        for rid, indices in pd.Series(race_ids).groupby(race_ids).groups.items():
            r_y = y.iloc[indices].values
            r_pred = y_pred[indices]
            
            if len(r_y) <= 1:
                continue
            
            top_idx = int(np.argmax(r_pred))
            if r_y[top_idx] == 1:
                top1_correct += 1
            total_races += 1
        
        if total_races > 0:
            metrics["top1_accuracy"] = float(top1_correct / total_races)

        # 6. EVãƒ™ãƒ¼ã‚¹å›åç‡
        if odds is not None:
            threshold = ev_threshold if ev_threshold is not None else self.config.ev_threshold
            metrics["recovery_rate_ev"] = self._calculate_ev_based_recovery(
                y_pred=y_pred,
                y_true=y,
                race_ids=race_ids,
                odds=odds,
                threshold=threshold,
            )

        return metrics

    def _calculate_ev_based_recovery(
        self,
        y_pred: np.ndarray,
        y_true: pd.Series,
        race_ids: pd.Series,
        odds: pd.Series,
        threshold: float,
    ) -> float:
        """
        EVï¼ˆæœŸå¾…å€¤ï¼‰ãƒ™ãƒ¼ã‚¹ã®å›åç‡ã‚’è¨ˆç®—ï¼ˆv1.1æ”¹å–„ç‰ˆï¼‰
        
        ğŸ”¥ v1.1: docstringè¿½åŠ ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„
        
        è¨ˆç®—æ–¹æ³•:
        1. å„é¦¬ã®EV = p * oddsã‚’è¨ˆç®—
        2. EV > 1.0 ã‹ã¤ p > thresholdã®é¦¬ã‚’è³¼å…¥
        3. ãƒ¬ãƒ¼ã‚¹å˜ä½ã§100å††ã‚’è³¼å…¥é¦¬ã«å‡ç­‰é…åˆ†
        4. ç·å›åé¡ / ç·æŠ•è³‡é¡
        
        Args:
            y_pred: äºˆæ¸¬ç¢ºç‡
            y_true: çœŸã®ãƒ©ãƒ™ãƒ«ï¼ˆ0/1ï¼‰
            race_ids: ãƒ¬ãƒ¼ã‚¹ID
            odds: ã‚ªãƒƒã‚º
            threshold: è³¼å…¥ã™ã‚‹æœ€ä½ç¢ºç‡
        
        Returns:
            å›åç‡ï¼ˆtotal_return / total_betï¼‰
        """
        total_bet = 0.0
        total_return = 0.0

        for rid, indices in pd.Series(race_ids).groupby(race_ids).groups.items():
            r_pred = y_pred[indices]
            r_true = y_true.iloc[indices].values
            r_odds = odds.iloc[indices].values

            if len(r_pred) <= 1:
                continue

            # EVè¨ˆç®—
            ev = r_pred * r_odds
            buy_mask = (ev > 1.0) & (r_pred > threshold)

            if not np.any(buy_mask):
                continue

            # å‡ç­‰è³¼å…¥
            n_buy = int(np.sum(buy_mask))
            bet_per_horse = 100.0 / n_buy
            total_bet += 100.0

            # é…å½“è¨ˆç®—
            for idx in np.where(buy_mask)[0]:
                if r_true[idx] == 1:
                    total_return += bet_per_horse * r_odds[idx]

        if total_bet == 0:
            return 0.0

        return float(total_return / total_bet)

    # ------------------------------------------------------------------
    # ãƒ¢ãƒ‡ãƒ«ã®å¯è¦–åŒ–ãƒ»æ°¸ç¶šåŒ–ï¼ˆv1.1æ”¹å–„ç‰ˆï¼‰
    # ------------------------------------------------------------------
    def get_feature_importance(
        self,
        importance_type: str = "gain",
        top_n: Optional[int] = 30,
    ) -> pd.DataFrame:
        """
        ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—
        
        Args:
            importance_type: é‡è¦åº¦ã‚¿ã‚¤ãƒ—ï¼ˆ"gain", "split"ç­‰ï¼‰
            top_n: ä¸Šä½Nä»¶ã‚’å–å¾—ï¼ˆNoneã®å ´åˆã¯å…¨ä»¶ï¼‰
        
        Returns:
            ç‰¹å¾´é‡é‡è¦åº¦DataFrame
        
        Raises:
            ValueError: ãƒ¢ãƒ‡ãƒ«ãŒæœªå­¦ç¿’ã®å ´åˆ
        """
        if not self._fitted or self.model is None:
            raise ValueError("BaseWinModel ãŒã¾ã å­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

        importances = self.model.feature_importance(importance_type=importance_type)
        df = pd.DataFrame(
            {
                "feature": self.feature_cols,
                "importance": importances,
            }
        ).sort_values("importance", ascending=False)
        
        if top_n is not None:
            df = df.head(top_n)
        
        return df

    def save(self, path: str) -> None:
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ï¼ˆv1.1æ”¹å–„ç‰ˆï¼‰
        
        ğŸ”¥ v1.1: ãƒ‘ã‚¹ç®¡ç†æ˜ç¢ºåŒ–
        
        Args:
            path: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆä¾‹: "model.txt"ï¼‰
        
        ä¿å­˜å†…å®¹:
        - {path}: LightGBMãƒ¢ãƒ‡ãƒ«
        - {path}_meta.json: ãƒ¡ã‚¿æƒ…å ±ï¼ˆç‰¹å¾´é‡åç­‰ï¼‰
        
        Raises:
            ValueError: ãƒ¢ãƒ‡ãƒ«ãŒæœªå­¦ç¿’ã®å ´åˆ
        """
        if not self._fitted or self.model is None:
            raise ValueError("BaseWinModel ãŒã¾ã å­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        self.model.save_model(path)

        # ãƒ¡ã‚¿æƒ…å ±ä¿å­˜
        meta = {
            "version": self.VERSION,
            "feature_cols": self.feature_cols,
            "categorical_features": self.categorical_features,
            "config": {
                "lgbm_params": self.config.lgbm_params,
                "num_boost_round": self.config.num_boost_round,
                "early_stopping_rounds": self.config.early_stopping_rounds,
                "ev_threshold": self.config.ev_threshold,
                "verbose": self.config.verbose,
            },
        }

        import json
        from pathlib import Path

        # ğŸ”¥ v1.1: ãƒ‘ã‚¹ç®¡ç†æ˜ç¢ºåŒ–
        model_path = Path(path)
        meta_path = model_path.parent / f"{model_path.stem}_meta.json"
        
        with meta_path.open("w", encoding="utf-8") as f:
            json.dump(meta, f, ensure_ascii=False, indent=2)

    def load(self, path: str) -> None:
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆv1.1æ”¹å–„ç‰ˆï¼‰
        
        Args:
            path: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
        """
        from pathlib import Path
        import json
        
        model_path = Path(path)
        if not model_path.exists():
            raise FileNotFoundError(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}")
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        self.model = lgb.Booster(model_file=path)
        self._fitted = True

        # ãƒ¡ã‚¿æƒ…å ±èª­ã¿è¾¼ã¿
        meta_path = model_path.parent / f"{model_path.stem}_meta.json"
        if meta_path.exists():
            with meta_path.open("r", encoding="utf-8") as f:
                meta = json.load(f)
            
            self.feature_cols = meta.get("feature_cols", [])
            self.categorical_features = meta.get("categorical_features", [])
            
            cfg = meta.get("config", {})
            self.config.lgbm_params = cfg.get("lgbm_params", self.config.lgbm_params)
            self.config.num_boost_round = cfg.get("num_boost_round", self.config.num_boost_round)
            self.config.early_stopping_rounds = cfg.get("early_stopping_rounds", self.config.early_stopping_rounds)
            self.config.ev_threshold = cfg.get("ev_threshold", self.config.ev_threshold)
            self.config.verbose = cfg.get("verbose", self.config.verbose)
        else:
            warnings.warn(f"ãƒ¡ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {meta_path}")


# ----------------------------------------------------------------------
# è£œåŠ©é–¢æ•°
# ----------------------------------------------------------------------
def create_win_labels(
    finish_positions: pd.Series,
    positive_up_to: int = 1,
) -> pd.Series:
    """
    ç€é †ã‹ã‚‰ win_flag ã‚’ä½œæˆ
    
    Args:
        finish_positions: ç€é †ï¼ˆ1,2,3,...ï¼‰
        positive_up_to: ä½•ç€ã¾ã§ 1 ã¨ã™ã‚‹ã‹ï¼ˆ1 or 2 æ¨å¥¨ï¼‰
    
    Returns:
        win_flagï¼ˆ0/1ï¼‰ã® Series
    
    Example:
        >>> finish_positions = pd.Series([1, 3, 2, 5])
        >>> create_win_labels(finish_positions, positive_up_to=1)
        0    1
        1    0
        2    0
        3    0
        dtype: int64
    """
    return (finish_positions <= positive_up_to).astype(int)


def example_usage():
    """ä½¿ç”¨ä¾‹ï¼ˆv1.1ï¼‰"""
    
    print("=" * 80)
    print("BaseWinModel v1.1 - ä½¿ç”¨ä¾‹ï¼ˆãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³å®Œæˆç‰ˆï¼‰")
    print("=" * 80)
    
    print("\nâœ… v1.1å®Œæˆ - å®Ÿå‹™ãƒ¬ãƒ™ãƒ«å®Œå…¨ä¿®æ­£")
    print("  - predict_for_race()éæ¨å¥¨åŒ–ï¼ˆå¤–éƒ¨ãƒ˜ãƒ«ãƒ‘ãƒ¼æ¨å¥¨ï¼‰")
    print("  - ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡åˆ¤å®šæ”¹å–„")
    print("  - best_iterationå–å¾—æ”¹å–„")
    print("  - early_stoppingæ”¹å–„ï¼ˆval_dfãŒãªã„å ´åˆã¯ç„¡åŠ¹åŒ–ï¼‰")
    print("  - positive_up_toå‰Šé™¤")
    print("  - NDCGä¿®æ­£ï¼ˆå˜ç€ã®ã¿è©•ä¾¡ï¼‰")
    print("  - è©•ä¾¡é–¢æ•°æ”¹å–„ï¼ˆä¾‹å¤–å‡¦ç†ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼‰")
    print("  - docstringå®Œå…¨è¿½åŠ ")
    print("  - å‹ãƒ’ãƒ³ãƒˆå®Œå…¨è¿½åŠ ")
    print("  - save/loadæ”¹å–„")
    print("  - feature_colsè‡ªå‹•æ¨å®š")
    print("  - EVãƒ™ãƒ¼ã‚¹å›åç‡é–¾å€¤è¨­å®šåŒ–")


if __name__ == "__main__":
    example_usage()
