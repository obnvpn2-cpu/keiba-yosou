"""
TimelineManager: ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã‚’é˜²ãæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ç®¡ç†ï¼ˆv5.1 - å®Ÿé‹ç”¨å®Œæˆç‰ˆï¼‰

v5.1ï¼ˆ2024-12-04ï¼‰: ChatGPTæœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾å¿œ
ğŸ”¥ å®Ÿé‹ç”¨ãƒ¬ãƒ™ãƒ«å®Œæˆ:
1. RESULTãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å³å¯†åŒ–ï¼ˆèª¤çˆ†é˜²æ­¢ï¼‰
2. ã‚ªãƒƒã‚ºãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æœ€çµ‚ã‚ªãƒƒã‚ºã®ã¿ã«é™å®š
3. ç¸¦æŒã¡ãƒ†ãƒ¼ãƒ–ãƒ«ã§feature_nameã”ã¨ã«æœ€æ–°è¡Œã®ã¿å–å¾—
4. strict_mode=Trueã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«å¤‰æ›´
5. æ¨ªæŒã¡ã®è­¦å‘Šè¿½åŠ 

v5.0: ã‚«ãƒ©ãƒ åãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã€ç¸¦æŒã¡å¯¾å¿œã€horse_idå˜ä½ç®¡ç†
v4.0: éå»æˆç¸¾åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«åŒ–ã€ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å°å…¥
v3.0: ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¿ã‚¤ãƒŸãƒ³ã‚°ç®¡ç†ã€race_timeè€ƒæ…®
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta, time
from typing import List, Tuple, Dict, Optional, Set
from dataclasses import dataclass
from dateutil.relativedelta import relativedelta
from zoneinfo import ZoneInfo
from enum import Enum
import warnings
import re


class DataAvailability(Enum):
    """ãƒ‡ãƒ¼ã‚¿ã®å–å¾—å¯èƒ½æ™‚ç‚¹ã‚’å®šç¾©"""
    PRE_RACE = 'pre_race'
    MORNING = 'morning'
    PADDOCK = 'paddock'
    JUST_BEFORE = 'just_before'
    RESULT = 'result'


# æœ€å°é™ã®FEATURE_AVAILABILITY
FEATURE_AVAILABILITY = {
    'race_id': DataAvailability.PRE_RACE,
    'horse_id': DataAvailability.PRE_RACE,
    'race_date': DataAvailability.PRE_RACE,
    'finish_position': DataAvailability.RESULT,
    'finish_time': DataAvailability.RESULT,
    'ç€é †': DataAvailability.RESULT,
    'ç€å·®': DataAvailability.RESULT,
}

# ğŸ”¥ v5.1: ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°å³å¯†åŒ–ï¼ˆèª¤çˆ†é˜²æ­¢ï¼‰
COLUMN_PATTERNS = {
    # RESULTï¼ˆå³å¯†ã«é™å®šï¼‰
    DataAvailability.RESULT: [
        r'^finish_position$', r'^finish_time$', r'^final_3f$', r'^final_3F$',
        r'.*ç€é †.*', r'.*ç€å·®.*', r'.*ç€æ™‚é–“.*',
        r'.*ä¸ŠãŒã‚Š.*3[fF].*', r'.*ä¸ŠãŒã‚Š.*ã‚¿ã‚¤ãƒ .*',
        r'.*é€šéé †.*', r'.*ã‚³ãƒ¼ãƒŠãƒ¼.*é€šé.*', r'.*passing.*order.*',
        r'.*prize.*money.*', r'.*æ‰•æˆ».*', r'.*payout.*',
        r'.*äººæ°—çµæœ.*', r'.*final.*popularity.*'
    ],
    
    # JUST_BEFOREï¼ˆæœ€çµ‚ã‚ªãƒƒã‚ºã®ã¿ï¼‰
    DataAvailability.JUST_BEFORE: [
        r'^odds$', r'^odds_win$', r'^odds_place$', r'^odds_show$',
        r'^popularity$', r'^äººæ°—$', r'^äººæ°—é †ä½$',
        r'.*æœ€çµ‚.*ã‚ªãƒƒã‚º.*', r'.*ç›´å‰.*ã‚ªãƒƒã‚º.*'
    ],
    
    # PADDOCKï¼ˆé¦¬ä½“é‡ã®ã¿ï¼‰
    DataAvailability.PADDOCK: [
        r'^weight$', r'^horse_weight$', r'^weight_change$',
        r'.*é¦¬ä½“é‡$', r'.*ä½“é‡å¢—æ¸›.*', r'.*ä½“é‡å¤‰åŒ–.*'
    ],
    
    # MORNINGï¼ˆå½“æ—¥æœãƒ‡ãƒ¼ã‚¿ï¼‰
    DataAvailability.MORNING: [
        r'.*moisture.*', r'.*cushion.*', r'^track_condition$',
        r'.*é¦¬å ´çŠ¶æ…‹.*', r'.*weather$', r'.*å¤©å€™.*', r'.*å¤©æ°—.*',
        r'.*baba.*index.*', r'.*é¦¬å ´æŒ‡æ•°.*'
    ],
}


@dataclass
class DataSplit:
    """ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã®æƒ…å ±ã‚’ä¿æŒ"""
    fold: int
    train_start: datetime
    train_end: datetime
    test_start: datetime
    test_end: datetime
    train_indices: np.ndarray
    test_indices: np.ndarray


class TimelineManager:
    """
    æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®ç®¡ç†ã¨ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰CVï¼ˆv5.1 - å®Ÿé‹ç”¨å®Œæˆç‰ˆï¼‰
    
    ğŸ”¥ v5.1ã§ã®é‡è¦ãªå¤‰æ›´ï¼ˆChatGPTæœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾å¿œï¼‰:
    1. RESULTãƒ‘ã‚¿ãƒ¼ãƒ³å³å¯†åŒ–ï¼ˆtimeç­‰ã®æ±ç”¨å˜èªã‚’é™¤å¤–ï¼‰
    2. ã‚ªãƒƒã‚ºãƒ‘ã‚¿ãƒ¼ãƒ³å³å¯†åŒ–ï¼ˆæœ€çµ‚ã‚ªãƒƒã‚ºã®ã¿ï¼‰
    3. ç¸¦æŒã¡ãƒ†ãƒ¼ãƒ–ãƒ«ã§feature_nameã”ã¨ã«æœ€æ–°è¡Œã®ã¿å–å¾—
    4. strict_mode=Trueã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆå®‰å…¨ç¬¬ä¸€ï¼‰
    5. æ¨ªæŒã¡DataFrameã®å ´åˆã¯è­¦å‘Šã‚’è¡¨ç¤º
    """
    
    def __init__(
        self,
        data: pd.DataFrame,
        past_performance_table: Optional[pd.DataFrame] = None,
        time_series_features_table: Optional[pd.DataFrame] = None,
        date_column: str = 'race_date',
        time_column: Optional[str] = None,
        cutoff_time: time = time(15, 0),
        tz: str = 'Asia/Tokyo',
        strict_mode: bool = True,
        auto_infer_levels: bool = True
    ):
        """
        Args:
            data: ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆDataFrameï¼‰
            past_performance_table: éå»æˆç¸¾ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ¨å¥¨ï¼‰
            time_series_features_table: ç¸¦æŒã¡æ™‚ç‚¹ç®¡ç†ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ¨å¥¨ï¼‰
            date_column: æ—¥ä»˜ã‚«ãƒ©ãƒ å
            time_column: ãƒ¬ãƒ¼ã‚¹æ™‚åˆ»ã‚«ãƒ©ãƒ å
            cutoff_time: ãƒ‡ãƒ¼ã‚¿å–å¾—åŸºæº–æ™‚åˆ»
            tz: ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³
            strict_mode: å³æ ¼ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰ğŸ”¥
            auto_infer_levels: ã‚«ãƒ©ãƒ åã‹ã‚‰ãƒ¬ãƒ™ãƒ«è‡ªå‹•æ¨å®š
        """
        self.data = data.copy()
        self.past_performance_table = past_performance_table
        self.time_series_features_table = time_series_features_table
        self.date_column = date_column
        self.time_column = time_column
        self.cutoff_time = cutoff_time
        self.tz = ZoneInfo(tz)
        self.strict_mode = strict_mode
        self.auto_infer_levels = auto_infer_levels
        
        # å¿…é ˆã‚«ãƒ©ãƒ ãƒã‚§ãƒƒã‚¯
        required_columns = ['race_id', 'horse_id', date_column]
        missing = [col for col in required_columns if col not in self.data.columns]
        if missing:
            raise ValueError(f"å¿…é ˆã‚«ãƒ©ãƒ ãŒä¸è¶³: {missing}")
        
        # éå»æˆç¸¾ãƒ†ãƒ¼ãƒ–ãƒ«æ¤œè¨¼
        if past_performance_table is not None:
            required_perf_cols = ['horse_id', 'as_of_date']
            missing_perf = [c for c in required_perf_cols if c not in past_performance_table.columns]
            if missing_perf:
                warnings.warn(f"past_performance_tableã«æ¨å¥¨ã‚«ãƒ©ãƒ ãŒä¸è¶³: {missing_perf}")
        
        # ğŸ”¥ v5.1: ç¸¦æŒã¡æ™‚ç‚¹ç®¡ç†ãƒ†ãƒ¼ãƒ–ãƒ«æ¤œè¨¼
        if time_series_features_table is not None:
            required_ts_cols = ['race_id', 'feature_name', 'value', 'timestamp']
            missing_ts = [c for c in required_ts_cols if c not in time_series_features_table.columns]
            if missing_ts:
                raise ValueError(f"time_series_features_tableã«å¿…é ˆã‚«ãƒ©ãƒ ãŒä¸è¶³: {missing_ts}")
            
            if not pd.api.types.is_datetime64_any_dtype(time_series_features_table['timestamp']):
                self.time_series_features_table['timestamp'] = pd.to_datetime(
                    time_series_features_table['timestamp']
                )
        else:
            # ğŸ”¥ v5.1: æ¨ªæŒã¡ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã¿ã®å ´åˆã¯è­¦å‘Š
            warnings.warn(
                "time_series_features_tableãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
                "æ¨ªæŒã¡DataFrameã®ã¿ã§ã¯æ™‚ç‚¹ç®¡ç†ãŒä¸å®Œå…¨ã§ã™ã€‚\n"
                "æœ¬ç•ªé‹ç”¨ã§ã¯ time_series_features_table ã®ä½¿ç”¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚",
                UserWarning
            )
        
        # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ
        self.data = self.data.sort_values(date_column).reset_index(drop=True)
        
        # æ—¥ä»˜ã‚’datetimeã«å¤‰æ›
        if not pd.api.types.is_datetime64_any_dtype(self.data[date_column]):
            self.data[self.date_column] = pd.to_datetime(self.data[date_column])
        
        self._past_performance_cache = {}
        
        # ã‚«ãƒ©ãƒ ãƒ¬ãƒ™ãƒ«ã‚’è‡ªå‹•æ¨å®šã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._column_level_cache = {}
        if auto_infer_levels:
            self._build_column_level_cache()
    
    def _build_column_level_cache(self):
        """ã‚«ãƒ©ãƒ åã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒ™ãƒ«ã‚’è‡ªå‹•æ¨å®šã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
        for col in self.data.columns:
            if col in ['index', 'level_0']:
                continue
            
            if col in FEATURE_AVAILABILITY:
                self._column_level_cache[col] = FEATURE_AVAILABILITY[col]
                continue
            
            inferred_level = self._infer_column_level(col)
            self._column_level_cache[col] = inferred_level
    
    def _infer_column_level(self, column: str) -> DataAvailability:
        """
        ã‚«ãƒ©ãƒ åã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒ™ãƒ«ã‚’æ¨å®šï¼ˆv5.1å³å¯†åŒ–ç‰ˆï¼‰
        
        Args:
            column: ã‚«ãƒ©ãƒ å
        
        Returns:
            æ¨å®šã•ã‚ŒãŸDataAvailability
        """
        # ğŸ”¥ v5.1: ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ï¼ˆå³å¯†åŒ–ï¼‰
        for level, patterns in COLUMN_PATTERNS.items():
            for pattern in patterns:
                if re.match(pattern, column, re.IGNORECASE):
                    return level
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯PRE_RACE
        return DataAvailability.PRE_RACE
    
    def walk_forward_split(
        self,
        n_splits: int = 5,
        test_size_months: int = 3,
        gap_days: int = 0,
        min_train_months: int = 12
    ) -> List[DataSplit]:
        """ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰CVç”¨ã®ãƒ‡ãƒ¼ã‚¿åˆ†å‰²"""
        
        min_date = self.data[self.date_column].min()
        max_date = self.data[self.date_column].max()
        
        test_start_dates = []
        current = min_date + relativedelta(months=min_train_months)
        
        while current + relativedelta(months=test_size_months) <= max_date:
            test_start_dates.append(current)
            current += relativedelta(months=test_size_months)
            
            if len(test_start_dates) >= n_splits:
                break
        
        if len(test_start_dates) == 0:
            raise ValueError(
                f"ãƒ‡ãƒ¼ã‚¿æœŸé–“ãŒçŸ­ã™ãã¾ã™ã€‚æœ€å°è¦ä»¶: {min_train_months + test_size_months}ãƒ¶æœˆ"
            )
        
        splits = []
        
        for fold, test_start in enumerate(test_start_dates):
            test_end = test_start + relativedelta(months=test_size_months)
            train_end = test_start - timedelta(days=gap_days)
            train_start = min_date
            
            train_mask = (self.data[self.date_column] >= train_start) & \
                        (self.data[self.date_column] < train_end)
            test_mask = (self.data[self.date_column] >= test_start) & \
                       (self.data[self.date_column] < test_end)
            
            train_indices = self.data[train_mask].index.to_numpy()
            test_indices = self.data[test_mask].index.to_numpy()
            
            if len(train_indices) > 0 and len(test_indices) > 0:
                split = DataSplit(
                    fold=fold + 1,
                    train_start=train_start,
                    train_end=train_end,
                    test_start=test_start,
                    test_end=test_end,
                    train_indices=train_indices,
                    test_indices=test_indices
                )
                splits.append(split)
        
        return splits
    
    def get_race_datetime(self, race_id: str) -> datetime:
        """ãƒ¬ãƒ¼ã‚¹ã®é–‹å‚¬æ—¥æ™‚ã‚’å–å¾—"""
        race_rows = self.data[self.data['race_id'] == race_id]
        if race_rows.empty:
            raise KeyError(f"race_id {race_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        race_date = race_rows.iloc[0][self.date_column]
        
        if self.time_column and self.time_column in race_rows.columns:
            race_time = race_rows.iloc[0][self.time_column]
            if pd.notna(race_time):
                if isinstance(race_time, str):
                    race_time = datetime.strptime(race_time, '%H:%M').time()
                race_datetime = datetime.combine(
                    race_date.date(),
                    race_time,
                    tzinfo=self.tz
                )
            else:
                race_datetime = datetime.combine(
                    race_date.date(),
                    time(15, 0),
                    tzinfo=self.tz
                )
        else:
            race_datetime = datetime.combine(
                race_date.date(),
                time(15, 0),
                tzinfo=self.tz
            )
        
        return race_datetime
    
    def get_safe_features(
        self,
        race_id: str,
        horse_id: str,
        as_of_datetime: Optional[datetime] = None,
        max_availability: DataAvailability = DataAvailability.PRE_RACE,
        include_features: Optional[Set[str]] = None
    ) -> Dict:
        """
        horse_idå˜ä½ã§å®‰å…¨ãªç‰¹å¾´é‡ã®ã¿å–å¾—ï¼ˆv5.1å®Ÿé‹ç”¨ç‰ˆï¼‰
        
        Args:
            race_id: ãƒ¬ãƒ¼ã‚¹ID
            horse_id: é¦¬ID
            as_of_datetime: ãƒ‡ãƒ¼ã‚¿å–å¾—æ™‚ç‚¹
            max_availability: å–å¾—å¯èƒ½ãªæœ€å¤§ãƒ¬ãƒ™ãƒ«
            include_features: æ˜ç¤ºçš„ã«å«ã‚ã‚‹ç‰¹å¾´é‡ã‚»ãƒƒãƒˆ
        
        Returns:
            å®‰å…¨ãªç‰¹å¾´é‡ã®è¾æ›¸
        """
        
        if as_of_datetime is None:
            as_of_datetime = self._calculate_as_of_datetime(race_id, max_availability)
        
        if as_of_datetime.tzinfo is None:
            as_of_datetime = as_of_datetime.replace(tzinfo=self.tz)
        
        safe_features = {
            'race_id': race_id,
            'horse_id': horse_id,
            'as_of_datetime': as_of_datetime,
            'max_availability': max_availability.value,
        }
        
        # ç¸¦æŒã¡æ™‚ç‚¹ç®¡ç†ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å„ªå…ˆ
        if self.time_series_features_table is not None:
            ts_features = self._get_features_from_time_series(
                race_id, horse_id, as_of_datetime, max_availability
            )
            safe_features.update(ts_features)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ¨ªæŒã¡DataFrame
            race_features = self._get_features_from_dataframe(
                race_id, horse_id, as_of_datetime, max_availability, include_features
            )
            safe_features.update(race_features)
        
        # éå»æˆç¸¾ã‚’è¿½åŠ 
        if self.past_performance_table is not None:
            past_perf = self._get_past_performance_from_table(horse_id, as_of_datetime)
            safe_features.update(past_perf)
        
        return safe_features
    
    def _get_features_from_time_series(
        self,
        race_id: str,
        horse_id: str,
        as_of_datetime: datetime,
        max_availability: DataAvailability
    ) -> Dict:
        """
        ç¸¦æŒã¡æ™‚ç‚¹ç®¡ç†ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ç‰¹å¾´é‡ã‚’å–å¾—ï¼ˆv5.1æ”¹å–„ç‰ˆï¼‰
        
        ğŸ”¥ v5.1: feature_nameã”ã¨ã«æœ€æ–°ã®1è¡Œã®ã¿å–å¾—
        
        Args:
            race_id: ãƒ¬ãƒ¼ã‚¹ID
            horse_id: é¦¬ID
            as_of_datetime: å–å¾—æ™‚ç‚¹
            max_availability: æœ€å¤§ãƒ¬ãƒ™ãƒ«
        
        Returns:
            ç‰¹å¾´é‡ã®è¾æ›¸
        """
        features = {}
        
        # race_idã§ãƒ•ã‚£ãƒ«ã‚¿
        ts_rows = self.time_series_features_table[
            self.time_series_features_table['race_id'] == race_id
        ]
        
        # horse_idã‚«ãƒ©ãƒ ãŒã‚ã‚Œã°ãƒ•ã‚£ãƒ«ã‚¿
        if 'horse_id' in self.time_series_features_table.columns:
            ts_rows = ts_rows[
                (ts_rows['horse_id'] == horse_id) | (ts_rows['horse_id'].isna())
            ]
        
        # as_of_datetimeä»¥å‰ã®ã¿
        ts_rows = ts_rows[ts_rows['timestamp'] <= as_of_datetime]
        
        # ğŸ”¥ v5.1: feature_nameã”ã¨ã«æœ€æ–°ã®1è¡Œã®ã¿å–å¾—
        if not ts_rows.empty:
            ts_rows = ts_rows.sort_values('timestamp', ascending=False)
            ts_rows = ts_rows.drop_duplicates(subset=['feature_name'], keep='first')
        
        for _, row in ts_rows.iterrows():
            feature_name = row['feature_name']
            value = row['value']
            
            # ãƒ¬ãƒ™ãƒ«ãƒã‚§ãƒƒã‚¯
            if 'availability_level' in row.index:
                feature_level = DataAvailability(row['availability_level'])
            else:
                feature_level = self._column_level_cache.get(
                    feature_name,
                    self._infer_column_level(feature_name)
                )
            
            # RESULTãƒ¬ãƒ™ãƒ«ã¯é™¤å¤–
            if feature_level == DataAvailability.RESULT:
                continue
            
            # max_availabilityãƒã‚§ãƒƒã‚¯
            if not self._is_available(feature_level, max_availability):
                continue
            
            features[feature_name] = value
        
        return features
    
    def _get_features_from_dataframe(
        self,
        race_id: str,
        horse_id: str,
        as_of_datetime: datetime,
        max_availability: DataAvailability,
        include_features: Optional[Set[str]] = None
    ) -> Dict:
        """æ¨ªæŒã¡DataFrameã‹ã‚‰ç‰¹å¾´é‡ã‚’å–å¾—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        
        race_rows = self.data[self.data['race_id'] == race_id]
        if race_rows.empty:
            raise KeyError(f"race_id {race_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        horse_row = race_rows[race_rows['horse_id'] == horse_id]
        if horse_row.empty:
            raise KeyError(f"horse_id {horse_id} ãŒ race_id {race_id} ã«å­˜åœ¨ã—ã¾ã›ã‚“")
        
        race_data = horse_row.iloc[0]
        features = {}
        
        for column in race_data.index:
            if column in ['index', 'level_0', 'race_id', 'horse_id']:
                continue
            
            # ãƒ¬ãƒ™ãƒ«å–å¾—
            feature_level = self._column_level_cache.get(
                column,
                self._infer_column_level(column)
            )
            
            # RESULTãƒ¬ãƒ™ãƒ«ã¯é™¤å¤–
            if feature_level == DataAvailability.RESULT:
                continue
            
            # max_availabilityãƒã‚§ãƒƒã‚¯
            if not self._is_available(feature_level, max_availability):
                continue
            
            # æœªçŸ¥ã®ãƒ¬ãƒ™ãƒ«ã¯è­¦å‘Šï¼ˆstrict_modeã®ã¿ï¼‰
            if feature_level is None and self.strict_mode:
                raise ValueError(f"åˆ— '{column}' ã®ãƒ¬ãƒ™ãƒ«ãŒä¸æ˜ã§ã™")
            
            if include_features is None or column in include_features:
                features[column] = race_data.get(column)
        
        return features
    
    def _get_past_performance_from_table(
        self,
        horse_id: str,
        as_of_datetime: datetime
    ) -> Dict:
        """éå»æˆç¸¾ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å–å¾—"""
        
        timestamp = int(as_of_datetime.timestamp())
        cache_key = (horse_id, timestamp)
        
        if cache_key in self._past_performance_cache:
            return self._past_performance_cache[cache_key]
        
        perf_rows = self.past_performance_table[
            (self.past_performance_table['horse_id'] == horse_id) &
            (pd.to_datetime(self.past_performance_table['as_of_date']) <= as_of_datetime)
        ].sort_values('as_of_date', ascending=False)
        
        if perf_rows.empty:
            result = {
                'past_3_avg_position': 9.0,
                'past_3_win_rate': 0.1,
                'past_5_avg_position': 9.0,
                'past_5_win_rate': 0.1,
            }
        else:
            latest = perf_rows.iloc[0]
            result = {
                'past_3_avg_position': latest.get('avg_position', 9.0),
                'past_3_win_rate': latest.get('win_rate', 0.1),
                'past_5_avg_position': latest.get('avg_position_5', 9.0),
                'past_5_win_rate': latest.get('win_rate_5', 0.1),
            }
        
        self._past_performance_cache[cache_key] = result
        return result
    
    def _is_available(
        self,
        feature_level: DataAvailability,
        max_level: DataAvailability
    ) -> bool:
        """ç‰¹å¾´é‡ãŒå–å¾—å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        level_order = {
            DataAvailability.PRE_RACE: 0,
            DataAvailability.MORNING: 1,
            DataAvailability.PADDOCK: 2,
            DataAvailability.JUST_BEFORE: 3,
            DataAvailability.RESULT: 4
        }
        
        return level_order[feature_level] <= level_order[max_level]
    
    def _calculate_as_of_datetime(
        self,
        race_id: str,
        max_availability: DataAvailability
    ) -> datetime:
        """max_availabilityã«å¿œã˜ãŸé©åˆ‡ãªas_of_datetimeã‚’è¨ˆç®—"""
        race_datetime = self.get_race_datetime(race_id)
        
        if max_availability == DataAvailability.PRE_RACE:
            return (race_datetime - timedelta(days=1)).replace(
                hour=self.cutoff_time.hour,
                minute=self.cutoff_time.minute,
                second=0,
                microsecond=0
            )
        
        elif max_availability == DataAvailability.MORNING:
            return race_datetime.replace(hour=9, minute=0, second=0, microsecond=0)
        
        elif max_availability == DataAvailability.PADDOCK:
            return race_datetime - timedelta(minutes=30)
        
        elif max_availability == DataAvailability.JUST_BEFORE:
            return race_datetime - timedelta(minutes=5)
        
        else:
            raise ValueError(f"RESULTãƒ¬ãƒ™ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã¯å–å¾—ã§ãã¾ã›ã‚“")
    
    def validate_no_leakage(
        self,
        feature_df: pd.DataFrame,
        target_df: pd.DataFrame,
        max_availability: DataAvailability = DataAvailability.PRE_RACE,
        show_samples: bool = True
    ) -> Tuple[bool, List[str]]:
        """ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ãŒãªã„ã‹æ¤œè¨¼"""
        
        issues = []
        
        for col in feature_df.columns:
            if col in ['index', 'level_0', 'race_id', 'horse_id']:
                continue
            
            feature_level = self._column_level_cache.get(
                col,
                self._infer_column_level(col)
            )
            
            if feature_level == DataAvailability.RESULT:
                issues.append(
                    f"âŒ è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: åˆ— '{col}' ã¯RESULTãƒ¬ãƒ™ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã§ã™ï¼ˆä½¿ç”¨ç¦æ­¢ï¼‰"
                )
                if show_samples:
                    sample = feature_df[col].head(3).tolist()
                    issues.append(f"   ã‚µãƒ³ãƒ—ãƒ«å€¤: {sample}")
            
            if not self._is_available(feature_level, max_availability):
                issues.append(
                    f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒ™ãƒ«é•å: åˆ— '{col}' ã¯ {feature_level.value} ãƒ¬ãƒ™ãƒ«ã§ã™ãŒã€"
                    f"max_availability ã¯ {max_availability.value} ã§ã™"
                )
                if show_samples:
                    sample = feature_df[col].head(3).tolist()
                    issues.append(f"   ã‚µãƒ³ãƒ—ãƒ«å€¤: {sample}")
        
        if not feature_df.index.equals(target_df.index):
            issues.append(
                f"âŒ feature_dfã¨target_dfã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒä¸€è‡´ã—ã¾ã›ã‚“\n"
                f"   feature_df: {len(feature_df)}è¡Œ, target_df: {len(target_df)}è¡Œ"
            )
        
        nan_cols = feature_df.columns[feature_df.isna().any()].tolist()
        if nan_cols:
            issues.append(
                f"âš ï¸  è­¦å‘Š: ä»¥ä¸‹ã®åˆ—ã«NaNãŒã‚ã‚Šã¾ã™: {nan_cols[:5]}"
                f"{'...' if len(nan_cols) > 5 else ''}"
            )
        
        inf_cols = feature_df.columns[
            np.isinf(feature_df.select_dtypes(include=[np.number])).any()
        ].tolist()
        if inf_cols:
            issues.append(f"âš ï¸  è­¦å‘Š: ä»¥ä¸‹ã®åˆ—ã«ç„¡é™å€¤ãŒã‚ã‚Šã¾ã™: {inf_cols}")
        
        is_safe = len([i for i in issues if i.startswith('âŒ')]) == 0
        
        return is_safe, issues
    
    def validate_split_integrity(
        self,
        splits: List[DataSplit]
    ) -> Tuple[bool, List[str]]:
        """ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰splitã®æ•´åˆæ€§ã‚’æ¤œè¨¼"""
        
        issues = []
        
        for i, split in enumerate(splits):
            if split.train_end >= split.test_start:
                issues.append(
                    f"âŒ Fold {split.fold}: train_end ({split.train_end}) ãŒ "
                    f"test_start ({split.test_start}) ä»¥é™ã§ã™"
                )
            
            if split.test_start >= split.test_end:
                issues.append(
                    f"âŒ Fold {split.fold}: testæœŸé–“ãŒä¸æ­£ã§ã™ "
                    f"({split.test_start} ~ {split.test_end})"
                )
            
            if len(split.train_indices) < 100:
                issues.append(
                    f"âš ï¸  è­¦å‘Š: Fold {split.fold}ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„ã§ã™ "
                    f"({len(split.train_indices)}ã‚µãƒ³ãƒ—ãƒ«)"
                )
            
            if len(split.test_indices) < 10:
                issues.append(
                    f"âš ï¸  è­¦å‘Š: Fold {split.fold}ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„ã§ã™ "
                    f"({len(split.test_indices)}ã‚µãƒ³ãƒ—ãƒ«)"
                )
            
            if i > 0:
                prev_split = splits[i - 1]
                if split.test_start < prev_split.test_end:
                    issues.append(
                        f"âŒ Fold {split.fold}ã¨Fold {prev_split.fold}ã® "
                        f"ãƒ†ã‚¹ãƒˆæœŸé–“ãŒé‡è¤‡ã—ã¦ã„ã¾ã™"
                    )
        
        is_valid = len([i for i in issues if i.startswith('âŒ')]) == 0
        
        return is_valid, issues
    
    def clear_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        self._past_performance_cache.clear()
    
    def register_feature(
        self,
        feature_name: str,
        availability: DataAvailability
    ):
        """ç‰¹å¾´é‡ã‚’ç™»éŒ²"""
        FEATURE_AVAILABILITY[feature_name] = availability
        self._column_level_cache[feature_name] = availability
        print(f"âœ… ç‰¹å¾´é‡ '{feature_name}' ã‚’ {availability.value} ãƒ¬ãƒ™ãƒ«ã¨ã—ã¦ç™»éŒ²ã—ã¾ã—ãŸ")
    
    def get_column_level(self, column: str) -> DataAvailability:
        """ã‚«ãƒ©ãƒ ã®ãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒ™ãƒ«ã‚’å–å¾—"""
        return self._column_level_cache.get(
            column,
            self._infer_column_level(column)
        )


def example_usage():
    """ä½¿ç”¨ä¾‹ï¼ˆv5.1å®Ÿé‹ç”¨ç‰ˆï¼‰"""
    
    print("=" * 80)
    print("TimelineManager v5.1 - ä½¿ç”¨ä¾‹ï¼ˆå®Ÿé‹ç”¨å®Œæˆç‰ˆï¼‰")
    print("=" * 80)
    
    dates = pd.date_range('2020-01-01', '2022-12-31', freq='W')
    
    data = []
    race_counter = 0
    
    for date in dates[:100]:
        for horse_num in range(1, 11):
            data.append({
                'race_id': f'race_{race_counter}',
                'race_date': date,
                'horse_id': f'horse_{np.random.randint(1, 50)}',
                'track_name': np.random.choice(['æ±äº¬', 'ä¸­å±±', 'äº¬éƒ½']),
                'distance': np.random.choice([1600, 1800, 2000]),
                'track_type': 'èŠ',
                'horse_number': horse_num,
                'horse_age': np.random.randint(3, 8),
                'gate_number': horse_num,
                'jockey_id': f'jockey_{np.random.randint(1, 50)}',
                'trainer_id': f'trainer_{np.random.randint(1, 30)}',
            })
        race_counter += 1
    
    df = pd.DataFrame(data)
    
    past_perf_data = []
    for horse_id in df['horse_id'].unique()[:20]:
        for date in pd.date_range('2020-01-01', '2022-12-31', freq='M'):
            past_perf_data.append({
                'horse_id': horse_id,
                'as_of_date': date,
                'avg_position': np.random.uniform(5, 10),
                'win_rate': np.random.uniform(0.05, 0.2),
            })
    
    past_perf_df = pd.DataFrame(past_perf_data)
    
    print("\nåˆæœŸåŒ–ä¸­...")
    tm = TimelineManager(
        df,
        past_performance_table=past_perf_df,
        date_column='race_date',
        cutoff_time=time(15, 0),
        tz='Asia/Tokyo',
        strict_mode=True,
        auto_infer_levels=True
    )
    
    print("âœ… TimelineManager v5.1 åˆæœŸåŒ–å®Œäº†")
    print(f"   ã‚«ãƒ©ãƒ ãƒ¬ãƒ™ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥: {len(tm._column_level_cache)}å€‹")
    
    print("\n" + "=" * 80)
    print("ã€1ã€‘ã‚«ãƒ©ãƒ ãƒ¬ãƒ™ãƒ«è‡ªå‹•æ¨å®šï¼ˆå³å¯†åŒ–ç‰ˆï¼‰")
    print("=" * 80)
    
    sample_columns = ['track_name', 'distance', 'horse_age']
    for col in sample_columns:
        if col in tm.data.columns:
            level = tm.get_column_level(col)
            print(f"  {col:20s} â†’ {level.value}")
    
    print("\n" + "=" * 80)
    print("ã€2ã€‘å®‰å…¨ãªç‰¹å¾´é‡å–å¾—")
    print("=" * 80)
    
    test_race_id = df['race_id'].iloc[0]
    test_horse_id = df['horse_id'].iloc[0]
    
    features = tm.get_safe_features(
        race_id=test_race_id,
        horse_id=test_horse_id,
        max_availability=DataAvailability.PRE_RACE
    )
    
    print(f"\nå–å¾—ã—ãŸç‰¹å¾´é‡: {len(features)}å€‹")
    print(f"  - track_name: {features.get('track_name')}")
    print(f"  - distance: {features.get('distance')}")
    print(f"  - éå»3èµ°å¹³å‡: {features.get('past_3_avg_position', 'N/A')}")
    
    print("\n" + "=" * 80)
    print("âœ… v5.1å®Œæˆ - å®Ÿé‹ç”¨ãƒ¬ãƒ™ãƒ«åˆ°é”")
    print("=" * 80)


if __name__ == "__main__":
    example_usage()
